# Алгоритмы и структуры данных, семестр 2

1. Если recopy mode делает копирование только тогда, когда происходит pop, то верно ли, что хватит 4 стеков?
2. Как избавиться от логарифмического замедления?
3. Если исключить случаи вроде "2 вершины объединены одним ребром", то верно ли, что вершина -- точка сочленения тогда и только тогда, когда она присоединена к мосту?
4. Пример, когда Дейкстра работает за экспоненту с отрицательными весами.

## Персистентные структуры данных

**Персистентная структура данных** -- это такая структура данных, которая, кроме своего текущего состояния, хранит информацию о прошлых состояниях.

Типы персистентности:

* **Частичная персистентность** -- персистентность, при которой можно делать запрос к любой из старых версий структуры данных, *но любые обновления можно делать только на последней версии структуры*, то есть версии представляют из себя **дерево-бамбук** (частный случай дерева).
* **Полная персистентность** -- персистентность, при которой допустимы и запросы, и обновления любой версии структуры данных. Версии представляют из себя **корневое дерево**.
* **Конфлюэнтная персистентность** -- персистентность, при которой возможно слияние нескольких структур данных.
* **Функциональная персистентность** -- персистентность, при которой запрещены уничтожающие присваивания (обновления *значений* запрещены). 

Как можно сделать структуру данных персистентной:

* **Полное копирование** -- метод, при котором сохраняется каждая версия структуры данных. Самый простой и очевидный метод. Требует много памяти и работает долго.
* **Копирование пути** -- метод, при котором обновляется только путь до обновляемой вершины. Используется, например, в деревьях поиска (*AVL-дерево*).
* **Метод толстых узлов** -- метод, при котором новая информация "дописывается" к вершине. Дает логарифмическое замедление.

# TODO: очередь на 6 стеках

## Поиск в глубину и его приложения

**Поиск в глубину (Depth first search, DFS)** -- это метод обхода узлов в графе. Асимптотика `O(V+E)`.

> **Лемма (о белых путях)**. Пусть дан граф `G`. Запустим `dfs(G)`. Остановим выполнение процедуры `dfs` от какой-то вершины u графа `G` в тот момент, когда вершина `u` была выкрашена в серый цвет (назовем его первым моментом времени). Заметим, что в данный момент в графе `G` есть как белые, так и черные, и серые вершины. Продолжим выполнение процедуры `dfs(u)` до того момента, когда вершина `u` станет черной (второй момент времени).
Тогда вершины графа `G\u`, бывшие черными и серыми в первый момент времени, не поменяют свой цвет ко второму моменту времени, а белые вершины либо останутся белыми, либо станут черными, причем черными станут те, что были достижимы от вершины u по белым путям.
>
> **Доказательство**.
> 1. Черные вершины останутся черными, потому что цвет может меняться только по схеме белый -> серый -> черный. Серые останутся серыми, потому что они лежат в стеке рекурсии и там и останутся. 
> 2. Если вершина была достижима по белому пути в первый момент времени, то она стала черной ко второму моменту времени, Иначе, это значит, что во второй момент времени на пути из `u` в `v` встретится ребро из черной вершины в белую.
> 3. Если вершина стала черной ко второму моменту времени, то она была достижима по белому пути в первый момент времени. Рассмотрим момент, когда вершина `v` стала черной: в этот момент существует cерый путь из `u` в `v`, а это значит, что в первый момент времени сущестовал белый путь из `u` в `v`, что и требовалось доказать. 

> **Теорема (о циклах)**. `dfs` не найдет обратных ребер тогда и только тогда, когда в ориентированном графе нет циклов.
> **Доказательство**.
> 1. `=>`: Пусть такое ребро `(v->u)` нашлось. Пройдем от `v` до `u`, затем по обратному ребру, получив цикл.
> 2. `<=`: Пусть есть цикл и `v` в него входит.
		- По **лемме о белых путях** существует `u` такое, что `v` -- предок `u`.
		- Из существования цикла существует ребро `(u->v)`.

> **Лемма (о вложении интервалов времени)**. Пусть `v` -- предок `u`. Тогда `tin[v] < tin[u] < tout[u] < tout[v]`. 

**Топологическая сортировка** -- это такая перенумеровка вершин графа, что из вершины с большим номером ребра ведут всегда в вершины с меньшим номером. Очевидно, что такой перенумеровки не существует, если в графе есть цикл. Иначе она существует. Докажем конструктивно (предъявив алгоритм).

1. Запустим обход в глубину и получим времена выхода `tout` для вершин графа.
2. Отсортируем вершины по времени выхода. Действительно, если обход в глубину от вершины `v` завершил работу, то были посещены все вершины, достижимые из нее, и, соответственно, их значение `tout` меньше.

**Компонента сильной связности в графе** -- это такое подмножество вершин, что каждая достижима из каждой.

**Алгоритм поиска компонент сильной связности (Косарайю)**:

1. Найти топологическую сортировку с помощью обхода в глубину.
2. Посетить вершины **транспонированного** графа в порядке **уменьшения** номеров в топологической сортировке.

**Конденсация графа `G`** -- это такой граф `G'`, что все вершины, которые находились в одной компоненте сильной связности, становятся одной вершиной.

> **Теорема**. Приведенный алгоритм корректен.
> 
> **Доказательство**. Как известно, нахождение топологической сортировки аналогично нахождению `tout`.
> 
> Рассмотрим следующее утверждение: если `C` и `C'` -- компоненты сильной связности и между ними есть ребро `(C->C')`, то `tout[C] > tout[C']`.
> + Если первой была достигнута компонента `C`, то это означает, что в какой-то момент времени обход в глубину заходит в некоторую вершину `v` компоненты `C`, при этом все остальные вершины компонент `C` и `C'` ещё не посещены. Но, так как по условию в графе конденсаций есть ребро `(C->C')`, то из вершины `v` будет достижима не только вся компонента `C`, но и вся компонента `C'`. Это означает, что при запуске из вершины `v` обход в глубину пройдёт по всем вершинам компонент `C` и `C'`, а, значит, они станут потомками по отношению к `v` в дереве обхода в глубину, то есть для любой вершины `u ∈ C ∪ С', u ≠ v` будет выполнено `tout(v) > tout(u)`.
> + Первой была достигнута компонента `C'`. Опять же, в какой-то момент времени обход в глубину заходит в некоторую вершину `v ∈ C'`, причём все остальные вершины компонент `C` и `C'` не посещены. Поскольку по условию в графе конденсаций существовало ребро `(C->C')`, то, вследствие ацикличности графа конденсаций, не существует обратного пути из `C'` в `C`, то есть обход в глубину из вершины `v` не достигнет вершин `C`. Это означает, что они будут посещены обходом в глубину позже, откуда и следует `tout(v) > tout(u)`.
> 
> Далее мы запускаемся от "*корневой*" компоненты, используя транспонированный граф. Несложно заметить, что тогда компоненты посещаются в порядке возрастания `tout`.

**Задача 2-SAT (2-satisfiability)** -- это задача распределения значений булевым переменным таким образом, чтобы они удовлетворяли всем наложенным ограничениям.

Задачу *2-SAT* можно представить в виде конъюнктивной нормальной формы, где в каждом выражении в скобках стоит ровно по две переменной, например: `(A ∨ C) ∧ (A ∨ ¬D) ∧ (B ∨ ¬D) ∧ (B ∨ ¬E) ∧ (C ∨ D)`.

**Алгоритм решения**:

1. Сперва заметим, что выражение вида `(A ∨ C)` эквивалентно `(¬B → A) ∧ (¬A → B)`.
2. Составим граф, где для каждой вершины `X` есть также вершина `¬X`, то есть число вершин равно `2*V`.
3. Теперь заметим, что если для какой-то переменной `X` выполняется, что из `X` достижимо `¬X`, а из `¬X` достижимо `X`, то задача решения не имеет. Действительно, какое бы значение для переменной `X` мы бы ни выбрали, мы всегда придём к противоречию -- что должно быть выбрано и обратное ему значение.
4. Для того, чтобы данная задача *2-SAT* имела решение, **необходимо и достаточно**, чтобы для любой переменной `X` вершины `X` и `¬X` находились **в разных компонентах сильной связности** графа.
5. Если `tout[X] > tout[¬X]`, то `X = true`, иначе `X = false`.

> **Теорема**. Приведенный алгоритм корректен.
> 
> Рассмотрим следующее утверждение: для того, чтобы данная задача *2-SAT* имела решение, необходимо и достаточно, чтобы для любой переменной `X` из вершины `X` нельзя достичь `¬X` и из вершины `¬X` нельзя достичь `X` одновременно. `(¬X → X) ∧ (X → ¬X)`.
> 
> - `=>` Пусть *2-SAT* имеет решение. Докажем, что не может быть такого, чтобы для любой переменной `X` из вершины `X` можно достичь `¬X` и из вершины `¬X` можно достичь `X` одновременно. `((X → ¬X) ∧ (¬X → X))`. Тогда чтобы из `¬X` достичь `X` (`¬X → X` было верным), `X` должен быть равен `true`. С другой стороны для того, чтобы из `X` достичь `¬X` (`X → ¬X` было верным), `X` должен быть равен `false`. Противоречие.
> - `<=` Пусть для любой переменной `X` из вершины `X` нельзя достичь `¬X` и из вершины `¬X` нельзя достичь `X` одновременно. Докажем, что этого достаточно, чтобы *2-SAT* имело решение. Пусть из *¬X* можно достичь `X`, но из вершины `X` нельзя достичь `¬X`. Докажем, что из `X` не достижимо такой `Y`, что из `Y` достижимо `¬Y`. (то есть `X → Y → ¬Y (X = 1, Y = 0)`). Если из `X → Y`, то `¬X ∨ Y`, отсюда следует `¬Y → ¬X`. Тогда `X → Y → ¬Y → ¬X`. Следовательно `X → ¬X`. Противоречие.

**Мост** -- такое ребро *неориентированного* графа, что его удаление влечет за собой увеличение числа компонент связности.

> **Лемма**. Запустим обход в глубину на графе. Если `v` -- предок `u`, то `(v, u)` -- мост тогда и только тогда, когда не существует обратного ребра из потомка `u` или самой `u` в предка `v` или саму `v`.
> 
> `=>`: Пусть данное ребро -- мост. Это гарантирует существование единственного пути из `v` в `u`, иначе можно было бы удалить это ребро и не нарушить связность графа.
> 
> `<=`: Если такого ребра нет, то очевидно, что существует только один путь из `v` в `u` и обратно: через данное ребро.

**Алгоритм поиска мостов**:

1. Теперь кроме того, что будет содержаться `tin`, также будет содержаться `up` -- массив, поддерживающий минимальное значение среди `tin[v]`, `tin[u], u - потомок`, `tin[t], t - вершины, достижимые из потомков`.
2. Во время поиска в глубину:
3. Если вершина `u` посещена, то присвоить `up[v] = min(up[v], tin[u])`.
4. Если вершина `u` не посещена -- посетить и присвоить `up[v] = min(up[v], up[u])`. Если `fup[u] > tin[v]`, то обратного ребра нет и мост найден.

**Точка сочленения** -- это такая вершина, что при ее удаление влечет за собой увеличение числа компонент связности.

**Алгоритм поиска точек сочленения** аналогичен поиску мостов. Когда мост найден -- выводим вершину `v`. Корень является точкой сочленения тогда и только тогда, когда из него нельзя обойти весь граф (число детей в дереве обхода больше 1).

**Эйлеров путь** -- путь, проходящий по всем ребрам графа по одному разу.

**Эйлеров цикл** -- эйлеров путь, который является замкнутым.

> **Лемма о рукопожатиях**. Любой конечный неориентированный граф имеет чётное число вершин нечётных степеней.
>
> **Доказательство**. При подсчете суммы степеней вершин графа каждое ребро `(v, u)` учитывается дважды: как исходящее из `v` и как исходящее из `u`. Следовательно, сумма всех степеней равна `2*E`. Предположим, что число вершин с нечетными степенями нечетно. Тогда сумма всех степеней тоже нечетна, а число `2*E` не может быть нечетным.

- *В неориентированном графе*.
	+ *Эйлеров путь* в графе существует тогда и только тогда, когда граф связный и содержит не более двух вершин нечётной степени. Ввиду леммы о рукопожатиях, число вершин с нечётной степенью должно быть четным. А значит эйлеров путь существует только тогда, когда это число равно нулю или двум. Причём когда оно равно нулю, эйлеров путь вырождается в эйлеров цикл.
	+ *Эйлеров цикл* существует тогда и только тогда, когда граф связный, и в нём отсутствуют вершины нечётной степени.
- *В ориентированном графе*.
	+ Эйлеров путь, не являющейся циклом, тогда и только тогда, когда существуют две вершины `p ∈ V` и `q ∈ V` (начальная и конечная вершины пути соответственно) такие, что их полустепени захода и полустепени исхода связаны равенствами `indeg(q) = outdeg(q) + 1` и `indeg(p) = outdeg(p) - 1`, а все остальные вершины имеют одинаковые полустепени исхода и захода: `outdeg(v) = indeg(v)`.
	+ `G = (V, A)` содержит *эйлеров цикл* тогда и только тогда, когда он сильно связан и для каждой вершины графа её входящая степень `indeg(v)` равна её исходящей степени `outdeg(v)`, то есть в вершину входит столько же ребер, сколько из неё и выходит.

# TODO: выделение компонент двусвязности, алгоритм поиска эйлерового пути/цикла

## Дерево доминаторов

Для графа `G` введем исток `s`. Говорят, что вершина `v` **доминирует над** `u`, если всякий путь из `s` в `u` проходит через вершину `v`. Пишется `v dom u`.

**Непосредственным доминатором** вершины `v` называется такая вершина `u`, что не существует такой вершины `t`, которая доминировала бы над `v` и при этом `t` лежит на пути между `v` и `u`. Другими словами, `u` -- ближайший к `v` доминатор. Пишется `idom(v) = u`.

Дерево доминаторов -- это дерево, составленное из доминаторов. Ребро `(v, u)` существует тогда и только тогда, когда `idom(u) = v`.

# TODO: построение за `O(MlogN)`

## Минимальный остов в неориентированном графе

**Остовное дерево** графа `G = (V, E)` -- ациклический связный (*дерево*) подграф данного связного неориентированного графа.

**Минимальное остовное дерево** графа `G = (V, E)` -- это его ациклический связный подграф, в который входят все его вершины, обладающий минимальным суммарным весом ребер.

**Ребро** `(u,v) ∉ G'` (`G'` -- *подграф некоторого минимального остовного дерева* `G`) называется **безопасным**, если при добавлении его в `G'`, `G' ∪ {(u,v)}` также является подграфом некоторого минимального остовного дерева графа `G`.

> **Лемма (о безопасном ребре)**. Рассмотрим связный неориентированный взвешенный граф `G = (V, E)` с весовой функцией `w: E → R`. Пусть `G' = (V, E′)` -- подграф некоторого минимального остовного дерева `G`, `⟨S,T⟩` -- разрез `G`, такой, что ни одно ребро из `E'` не пересекает разрез, а `(u,v)` -- ребро минимального веса среди всех ребер, пересекающих разрез `⟨S,T⟩`. Тогда ребро `e = (u, v)` является безопасным для `G'`.
> 
> **Доказательство**: Достроим `E'` до некоторого минимального остовного дерева, обозначим его `T_min`. Если ребро `e ∈ T_min`, то лемма доказана, поэтому рассмотрим случай, когда ребро `e ∉ T_min`. Рассмотрим путь в `T_min` от вершины `u` до вершины `v`. Так как эти вершины принадлежат разным долям разреза, то хотя бы одно ребро пути пересекает разрез, назовем его `e'`. По условию леммы `w(e) ⩽ w(e')`. Заменим ребро `e'` в `T_min` на ребро `e`. Полученное дерево также является минимальным остовным деревом графа `G`, поскольку все вершины `G` по-прежнему связаны и вес дерева не увеличился. Следовательно `E' ∪ {e}` можно дополнить до минимального остовного дерева в графе `G`, то есть ребро `e` -- безопасное.

*Алгоритмы построения минимального остовного дерева*:

**Алгоритм Краскала**:

- Отсортируем ребра по их весу.
- С использованием *DSU* будем добавлять (если вершины еще не соединены никаким путем) либо не добавлять ребро в минимальный остов.
- Асимптотика `O(MlogM)`.

# TODO: proof

**Алгоритм Прима**:

1. Для каждой вершины (кроме стартовой) будем поддерживать минимальное входящее в нее ребро.
2. Будем поддерживать кучу вершин, отсортированных по минимальному входящему ребру (аналогично алгоритму Дейкстры).
3. Когда посещаем вершину -- добавляем ребро к ответу.
4. Асимптотика `O(E+Vlog(E/V)logV)` для двоичной кучи, `O((E+V)logV)` для двоичного дерева и `O(E+VlogV)` для фибоначчиевой кучи.

> **Теорема**. Алгоритм Прима корректен.
>
> **Доказательство**. По поддерживаемым инвариантам после извлечения вершины `v` (`v` ≠ `r`) из `Q` ребро `(v, p(v))` является ребром минимального веса, пересекающим разрез `(F, Q)`. Значит, по лемме о безопасном ребре, оно безопасно. Алгоритм построения *MST*, добавляющий безопасные ребра, причём делающий это ровно `V - 1 раз`, корректен. 

**Алгоритм Борувки**:

1. Изначально каждая вершина графа `G` -- тривиальное дерево, а ребра не принадлежат никакому дереву. 
2. Для каждого дерева `T` найдем минимальное инцидентное ему ребро. Добавим все такие ребра (без повторений).
3. Повторяем шаг 2 пока в графе не останется только одно дерево `T`.
4. Асимптотика `O(ElogV)`.

> **Теорема**. Алгоритм Борувки корректен.
> 
> **Доказательство**. Очевидно, что в результате работы алгоритма получается дерево. Пусть T - минимальное остовное дерево графа G, а T' - дерево полученное после работы алгоритма. Покажем, что T = T'.
>
> Предположим обратное: `T ≠ T'`. Пусть ребро `e'` - первое добавленное ребро дерева `T'`, не принадлежащее дереву `T`. Пусть `P` - путь, соединяющий в дереве `T` вершины ребра `e'`. Понятно, что в момент, когда ребро `e'` добавляли, какое-то ребро `P` (назовем его `e`) не было добавлено. По алгоритму `e ⩾ e'`. Однако тогда `T - e + e'` - остовное дерево веса не превышающего вес дерева `T`. Получили противоречение. Следовательно `T = T'`. 

# TODO: алгоритм Фрейдмана-Тарьяна

## Минимальный ориентированный остов

# TODO: лемма о сжатии цикла, полиномиальный алгоритм, алгоритм двух китайцев

## Алгоритмы поиска кратчайшего пути во взвешенных графах

**Поиск в ширину (Breadth first search, BFS)** -- это метод обхода узлов в графе. *Может находить кратчайший путь в невзвешенном графе*. Асимптотика `O(V+E)`.

**0-k BFS** -- это разновидность *BFS*, предназначенная для использования на графах, где вес ребра -- это одно из чисел в пределах от 1 до `k`. Тогда для нахождения кратчайшего пути достаточно создать `k` очередей и выбирать вершину с минимальным номером очереди. Асимптотика `O(kV+E)`.

- Поддерживая список непустых очередей с помощью *кучи* можно ускорить до `O((V+E)logk)`.
- Можно оптимизировать до `O(V√k+E)` с помощью *sqrt-декомпозиции*.

**Алгоритм Дейкстры** (*работает только с неотрицательными весами ребер*):

1. Инициализируем все дистанции бесконечными, а вершину `s` -- нулевой дистанцией. Кладем `s` в кучу.
2. Пока куча не пуста: возьмем вершину `v` с минимальным текущим расстоянием и прорелаксируем ее.
3. Вернем кратчайшие расстояния.

> **Теорема**. Приведенный алгоритм корректен.
> 
> **Доказательство**. Докажем по индукции, что в момент посещения любой вершины `u`, `d(u) = D(u)`.
>
> 	- На первом шаге выбирается `s`, для неё выполнено: `D(s) = d(s) = 0`.
> 	- Пусть для `N` первых шагов алгоритм сработал верно и на `N+1` шагу выбрана вершина `u`. Докажем, что в этот момент `D(u) = d(u)`. Для начала отметим, что для любой вершины `v`, всегда выполняется `D(v) ⩾ d(v)` (алгоритм не может найти путь короче, чем кратчайший из всех существующих). Пусть `P` -- кратчайший путь из `s` в `u`, `v` -- первая непосещённая вершина на `P`, `z` -- предшествующая ей (следовательно, посещённая). Поскольку путь `P` кратчайший, его часть, ведущая из `s` через `z` в `v`, тоже кратчайшая, следовательно `d(v) = d(z) + w(zv)`. По предположению индукции, в момент посещения вершины `z` выполнялось `D(z) = d(z)`, следовательно, вершина `v` тогда получила метку не больше чем `D(z) + w(zv) = d(z) + w(zv) = D(v)`, следовательно, `D(v) = d(v)`. С другой стороны, поскольку сейчас мы выбрали вершину `u`, её метка минимальна среди непосещённых, то есть `D(u) ⩽ D(v) = d(v) ⩽ d(u)`, где второе неравенсто верно из-за ранее упомянутого определения вершины `v` в качестве первой непосещённой вершины на `P`, то есть вес пути до промежуточной вершины не превосходит веса пути до конечной вершины вследствие неотрицательности весовой функции. Комбинируя это с `D(u) ⩾ d(u)`, имеем `D(u) = d(u)`, что и требовалось доказать.
> 	- Поскольку алгоритм заканчивает работу, когда все вершины посещены, в этот момент `D(u) = d(u)` для всех `u`. 

*Ускорение с фибоначчиевой кучей* очевидно и тривиально: будем хранить указатель на узел в куче для каждой вершины и, если дистанция уменьшается, вместо того, чтобы добавлять в кучу новый узел, применим `decrease_key` на старом.

**Алгоритм Форда-Беллмана**:

1. Изначально `D[s] = 0, D[v] = ∞`.
2. На каждом из `V - 1 ` шагов рассматриваем все ребра и пытаемся улучшить ответ. Таким образом, на `k`-ом шаге мы найдем все пути длины k. Понятно, что на 0 шаге индукция верна, и на каждом шаге будет найдено ребро, которое установит кратчайший путь.
3. Асимптотика `O(VE)`.

Стоит обратить внимание на следующий факт: *алгоритм способен находить циклы отрицательного веса*. Введем `V`-ю итерацию. Действительно, если циклов отрицательного веса нет, то обновлений кратчайших путей не будет. Иначе найдется кратчайший путь, который имеет длину `V`, чего быть не может.

**Алгоритм SPFA (Shortest Path Faster Algorithm)** (улучшение алгоритма Форда-Беллмана):

1. Изначально `D[s] = 0, D[v] = ∞`, `s` добавим в очередь.
2. Пока очередь не пуста: возьмем вершину `v`. Попробуем улучшить для всех соседних вершин `u` результат. Если он был улучшен -- добавим вершину в очередь. Очевидно, что каждая вершина побывает в очереди в тот момент, когда для нее путь кратчайший.

**Алгоритм Флойда** (*находит кратчайшие пути между* **всеми** *парами вершин*):

1. Изначально `D[v, v] = 0`, если существует ребро `(v, u)` веса `w`, то `D[v, u] = w`, иначе `D[v, u] = ∞`.
2. Перебираем вершину, через которую путь пойдет, стартовую и конечную.

```
for k = 1 to n
	for i = 1 to n
		for j = 1 to n
			D[i, j] = min(D[i, j], D[i, k] + D[k, j])
```

## Алгоритм Торупа

# TODO

## Паросочетания

**Паросочетание** `M` -- это набор попарно несмежных рёбер графа.

**Мощность паросочетания** -- количество рёбер в нём.

**Наибольшее (или максимальное) паросочетание** -- паросочетание, мощность которого максимальна среди всех возможных паросочетаний в данном графе.

**Цепью** длины `k` назовём некоторый простой путь (то есть не содержащий повторяющихся вершин или рёбер), содержащий `k` рёбер.

**Чередующейся цепью** (в двудольном графе, относительно некоторого паросочетания) назовём цепь, в которой рёбра поочередно принадлежат/не принадлежат паросочетанию.

**Увеличивающей цепью** (в двудольном графе, относительно некоторого паросочетания) назовём чередующуюся цепь, у которой начальная и конечная вершины не принадлежат паросочетанию.

> **Теорема (Берж)**. Паросочетание является максимальным тогда и только тогда, когда не существует увеличивающих относительно него цепей.
> 
> **Доказательство**.
> 
> - `=>` 