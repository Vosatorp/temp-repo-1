# Алгоритмы и структуры данных, семестр 2

1. Если recopy mode делает копирование только тогда, когда происходит pop, то верно ли, что хватит 4 стеков?
2. Как избавиться от логарифмического замедления?
3. Если исключить случаи вроде "2 вершины объединены одним ребром", то верно ли, что вершина -- точка сочленения тогда и только тогда, когда она присоединена к мосту?
4. Пример, когда Дейкстра работает за экспоненту с отрицательными весами.
5. Разве не `4N+2` операции копирования во время паники?

## Персистентные структуры данных

**Персистентная структура данных** -- это такая структура данных, которая, кроме своего текущего состояния, хранит информацию о прошлых состояниях.

Типы персистентности:

* **Частичная персистентность** -- персистентность, при которой можно делать запрос к любой из старых версий структуры данных, *но любые обновления можно делать только на последней версии структуры*, то есть версии представляют из себя **дерево-бамбук** (частный случай дерева).
* **Полная персистентность** -- персистентность, при которой допустимы и запросы, и обновления любой версии структуры данных. Версии представляют из себя **корневое дерево**.
* **Конфлюэнтная персистентность** -- персистентность, при которой возможно слияние нескольких структур данных.
* **Функциональная персистентность** -- персистентность, при которой запрещены уничтожающие присваивания (обновления *значений* запрещены). 

Как можно сделать структуру данных персистентной:

* **Полное копирование** -- метод, при котором сохраняется каждая версия структуры данных. Самый простой и очевидный метод. Требует много памяти и работает долго.
* **Копирование пути** -- метод, при котором обновляется только путь до обновляемой вершины. Используется, например, в деревьях поиска (*AVL-дерево*).
* **Метод толстых узлов** -- метод, при котором новая информация "дописывается" к вершине. Дает логарифмическое замедление.

**Очередь на 6 стеках**.

Из-за того, что не понятно, как сделаь односвязный списое полностью персистентным, возникает закономерный вопрос: как сделать очередь полностью персистентной?

Для этого рассмотрим алгоритм на 2 стеках. Понятно, что для полность персистентной структуры он не подходит, потому что в некоторый момент может произойти `O(N)` операций перекопирования и из-за этого любой запрос к структуре, который заставит ее сделать такое число операций, будет иметь такую асимптотику в и по времени, и по памяти. Рассмотрим другую схему алгоритма.

Пусть у нас есть стеки `L` и `R`, как в первой варианции алгоритма: мы все так же добавляем и удаляем элементы из них соответственно. Введем понятие `recopy mode`: это режим стека, когда `L.size > R.size` (существует он для того, чтобы в дальнейшем на каждую операцию уходило ровно константное время). Также введем стеки `L'` и `R'`. Когда включается `recopy mode`, стеки `L` и `L'` меняются указателями (`L` выполняет ту же роль, но он теперь пуст). Теперь во время любой операции (`push` или `pop`) будем выполнять перекладывание из `L'` в `R'`. После того, как все элементы скопированы -- поменяем местами указатели на `R` и `R'`. Данный алгоритм не будет работать корректно: большое число операций `push` во время `recopy mode` не даст ему работать за константное время при любых условиях (также, если перекладывание будет выполняться только во время `pop`, то появляется проблема, что после большого числа `push` окажется `L.size >> R.size`, `recopy mode` включается второй раз и он уже не успеет сделать полное копирование).

Для того, чтобы алгоритм заработал, будем сперва все элементы из `R` перекладывать в `R'`, затем из `L'` в `R`, после -- из `R'` в `R`. С учетом того, что `L.size + R.size == 2N + 1`, получаем, что нам необходимо `~3N` копирований. Если делать по 3 копирования за раз, то выйдет `O(1)` на запросы `push` и `pop`. Но что делать с операцией `pop`? Структура стека `R` теперь сломана. Для этого нам понадобится еще один стек `Rc`, который на момент начала `recopy mode` будет аналогичен стеку `R`, из него и будем забирать элементы. Если режим обычный -- забираем элемент сразу из двух стеков `R` и `Rc`. 

Существует и такая проблема: после окончания `recopy mode` где-то должна содержаться копия `R`. Чтобы она была -- создадим еще один стек `Rc'`, в который будем копировать все те же элементы, что и в `R`, а затем поменяем местами `Rc` и `Rc'`.

Предпоследняя проблема: после `recopy mode` может случится, что в `R` будут лишние элементы (которые были в нем изначально, но не были удалены). Для решения данной проблемы добавим переменную `toCopy`, которая покажет, сколько элементов нужно переложить из `R'` в `R` на последней фазе. Изначально это число равно `2N + 1`, но с каждым `pop` значение `toCopy` уменьшается на 1.

Последняя проблема: необходимо уничтожить возможный мусор после `recopy mode` в `Rc'`. Будем делать `Rc'.pop` во время `pop`. Мусор в `R'` удаляется очень просто: достаточно элементы, которые нам не нужны согласно `toCopy`, просто никуда не класть.

## Поиск в глубину и его приложения

**Поиск в глубину (Depth first search, DFS)** -- это метод обхода узлов в графе. Асимптотика `O(V+E)`.

> **Лемма (о белых путях)**. Пусть дан граф `G`. Запустим `dfs(G)`. Остановим выполнение процедуры `dfs` от какой-то вершины u графа `G` в тот момент, когда вершина `u` была выкрашена в серый цвет (назовем его первым моментом времени). Заметим, что в данный момент в графе `G` есть как белые, так и черные, и серые вершины. Продолжим выполнение процедуры `dfs(u)` до того момента, когда вершина `u` станет черной (второй момент времени).
Тогда вершины графа `G\u`, бывшие черными и серыми в первый момент времени, не поменяют свой цвет ко второму моменту времени, а белые вершины либо останутся белыми, либо станут черными, причем черными станут те, что были достижимы от вершины u по белым путям.
>
> **Доказательство**.
> 1. Черные вершины останутся черными, потому что цвет может меняться только по схеме белый -> серый -> черный. Серые останутся серыми, потому что они лежат в стеке рекурсии и там и останутся. 
> 2. Если вершина была достижима по белому пути в первый момент времени, то она стала черной ко второму моменту времени, Иначе, это значит, что во второй момент времени на пути из `u` в `v` встретится ребро из черной вершины в белую.
> 3. Если вершина стала черной ко второму моменту времени, то она была достижима по белому пути в первый момент времени. Рассмотрим момент, когда вершина `v` стала черной: в этот момент существует cерый путь из `u` в `v`, а это значит, что в первый момент времени сущестовал белый путь из `u` в `v`, что и требовалось доказать. 

> **Теорема (о циклах)**. `dfs` не найдет обратных ребер тогда и только тогда, когда в ориентированном графе нет циклов.
> **Доказательство**.
> 1. `=>`: Пусть такое ребро `(v->u)` нашлось. Пройдем от `v` до `u`, затем по обратному ребру, получив цикл.
> 2. `<=`: Пусть есть цикл и `v` в него входит.
		- По **лемме о белых путях** существует `u` такое, что `v` -- предок `u`.
		- Из существования цикла существует ребро `(u->v)`.

> **Лемма (о вложении интервалов времени)**. Пусть `v` -- предок `u`. Тогда `tin[v] < tin[u] < tout[u] < tout[v]`. 

**Топологическая сортировка** -- это такая перенумеровка вершин графа, что из вершины с большим номером ребра ведут всегда в вершины с меньшим номером. Очевидно, что такой перенумеровки не существует, если в графе есть цикл. Иначе она существует. Докажем конструктивно (предъявив алгоритм).

1. Запустим обход в глубину и получим времена выхода `tout` для вершин графа.
2. Отсортируем вершины по времени выхода. Действительно, если обход в глубину от вершины `v` завершил работу, то были посещены все вершины, достижимые из нее, и, соответственно, их значение `tout` меньше.

**Компонента сильной связности в графе** -- это такое подмножество вершин, что каждая достижима из каждой.

**Алгоритм поиска компонент сильной связности (Косарайю)**:

1. Найти топологическую сортировку с помощью обхода в глубину.
2. Посетить вершины **транспонированного** графа в порядке **уменьшения** номеров в топологической сортировке.

**Конденсация графа `G`** -- это такой граф `G'`, что все вершины, которые находились в одной компоненте сильной связности, становятся одной вершиной.

> **Теорема**. Приведенный алгоритм корректен.
> 
> **Доказательство**. Как известно, нахождение топологической сортировки аналогично нахождению `tout`.
> 
> Рассмотрим следующее утверждение: если `C` и `C'` -- компоненты сильной связности и между ними есть ребро `(C->C')`, то `tout[C] > tout[C']`.
> + Если первой была достигнута компонента `C`, то это означает, что в какой-то момент времени обход в глубину заходит в некоторую вершину `v` компоненты `C`, при этом все остальные вершины компонент `C` и `C'` ещё не посещены. Но, так как по условию в графе конденсаций есть ребро `(C->C')`, то из вершины `v` будет достижима не только вся компонента `C`, но и вся компонента `C'`. Это означает, что при запуске из вершины `v` обход в глубину пройдёт по всем вершинам компонент `C` и `C'`, а, значит, они станут потомками по отношению к `v` в дереве обхода в глубину, то есть для любой вершины `u ∈ C ∪ С', u ≠ v` будет выполнено `tout(v) > tout(u)`.
> + Первой была достигнута компонента `C'`. Опять же, в какой-то момент времени обход в глубину заходит в некоторую вершину `v ∈ C'`, причём все остальные вершины компонент `C` и `C'` не посещены. Поскольку по условию в графе конденсаций существовало ребро `(C->C')`, то, вследствие ацикличности графа конденсаций, не существует обратного пути из `C'` в `C`, то есть обход в глубину из вершины `v` не достигнет вершин `C`. Это означает, что они будут посещены обходом в глубину позже, откуда и следует `tout(v) > tout(u)`.
> 
> Далее мы запускаемся от "*корневой*" компоненты, используя транспонированный граф. Несложно заметить, что тогда компоненты посещаются в порядке возрастания `tout`.

**Задача 2-SAT (2-satisfiability)** -- это задача распределения значений булевым переменным таким образом, чтобы они удовлетворяли всем наложенным ограничениям.

Задачу *2-SAT* можно представить в виде конъюнктивной нормальной формы, где в каждом выражении в скобках стоит ровно по две переменной, например: `(A ∨ C) ∧ (A ∨ ¬D) ∧ (B ∨ ¬D) ∧ (B ∨ ¬E) ∧ (C ∨ D)`.

**Алгоритм решения**:

1. Сперва заметим, что выражение вида `(A ∨ C)` эквивалентно `(¬B → A) ∧ (¬A → B)`.
2. Составим граф, где для каждой вершины `X` есть также вершина `¬X`, то есть число вершин равно `2*V`.
3. Теперь заметим, что если для какой-то переменной `X` выполняется, что из `X` достижимо `¬X`, а из `¬X` достижимо `X`, то задача решения не имеет. Действительно, какое бы значение для переменной `X` мы бы ни выбрали, мы всегда придём к противоречию -- что должно быть выбрано и обратное ему значение.
4. Для того, чтобы данная задача *2-SAT* имела решение, **необходимо и достаточно**, чтобы для любой переменной `X` вершины `X` и `¬X` находились **в разных компонентах сильной связности** графа.
5. Если `tout[X] > tout[¬X]`, то `X = true`, иначе `X = false`.

> **Теорема**. Приведенный алгоритм корректен.
> 
> Рассмотрим следующее утверждение: для того, чтобы данная задача *2-SAT* имела решение, необходимо и достаточно, чтобы для любой переменной `X` из вершины `X` нельзя достичь `¬X` и из вершины `¬X` нельзя достичь `X` одновременно. `(¬X → X) ∧ (X → ¬X)`.
> 
> - `=>` Пусть *2-SAT* имеет решение. Докажем, что не может быть такого, чтобы для любой переменной `X` из вершины `X` можно достичь `¬X` и из вершины `¬X` можно достичь `X` одновременно. `((X → ¬X) ∧ (¬X → X))`. Тогда чтобы из `¬X` достичь `X` (`¬X → X` было верным), `X` должен быть равен `true`. С другой стороны для того, чтобы из `X` достичь `¬X` (`X → ¬X` было верным), `X` должен быть равен `false`. Противоречие.
> - `<=` Пусть для любой переменной `X` из вершины `X` нельзя достичь `¬X` и из вершины `¬X` нельзя достичь `X` одновременно. Докажем, что этого достаточно, чтобы *2-SAT* имело решение. Пусть из *¬X* можно достичь `X`, но из вершины `X` нельзя достичь `¬X`. Докажем, что из `X` не достижимо такой `Y`, что из `Y` достижимо `¬Y`. (то есть `X → Y → ¬Y (X = 1, Y = 0)`). Если из `X → Y`, то `¬X ∨ Y`, отсюда следует `¬Y → ¬X`. Тогда `X → Y → ¬Y → ¬X`. Следовательно `X → ¬X`. Противоречие.

**Мост** -- такое ребро *неориентированного* графа, что его удаление влечет за собой увеличение числа компонент связности.

> **Лемма**. Запустим обход в глубину на графе. Если `v` -- предок `u`, то `(v, u)` -- мост тогда и только тогда, когда не существует обратного ребра из потомка `u` или самой `u` в предка `v` или саму `v`.
> 
> `=>`: Пусть данное ребро -- мост. Это гарантирует существование единственного пути из `v` в `u`, иначе можно было бы удалить это ребро и не нарушить связность графа.
> 
> `<=`: Если такого ребра нет, то очевидно, что существует только один путь из `v` в `u` и обратно: через данное ребро.

**Алгоритм поиска мостов**:

1. Теперь кроме того, что будет содержаться `tin`, также будет содержаться `up` -- массив, поддерживающий минимальное значение среди `tin[v]`, `tin[u], u - потомок`, `tin[t], t - вершины, достижимые из потомков`.
2. Во время поиска в глубину:
3. Если вершина `u` посещена, то присвоить `up[v] = min(up[v], tin[u])`.
4. Если вершина `u` не посещена -- посетить и присвоить `up[v] = min(up[v], up[u])`. Если `fup[u] > tin[v]`, то обратного ребра нет и мост найден.

**Точка сочленения** -- это такая вершина, что при ее удаление влечет за собой увеличение числа компонент связности.

**Алгоритм поиска точек сочленения** аналогичен поиску мостов. Когда мост найден -- выводим вершину `v`. Корень является точкой сочленения тогда и только тогда, когда из него нельзя обойти весь граф (число детей в дереве обхода больше 1).

**Эйлеров путь** -- путь, проходящий по всем ребрам графа по одному разу.

**Эйлеров цикл** -- эйлеров путь, который является замкнутым.

> **Лемма о рукопожатиях**. Любой конечный неориентированный граф имеет чётное число вершин нечётных степеней.
>
> **Доказательство**. При подсчете суммы степеней вершин графа каждое ребро `(v, u)` учитывается дважды: как исходящее из `v` и как исходящее из `u`. Следовательно, сумма всех степеней равна `2*E`. Предположим, что число вершин с нечетными степенями нечетно. Тогда сумма всех степеней тоже нечетна, а число `2*E` не может быть нечетным.

- *В неориентированном графе*.
	+ *Эйлеров путь* в графе существует тогда и только тогда, когда граф связный и содержит не более двух вершин нечётной степени. Ввиду леммы о рукопожатиях, число вершин с нечётной степенью должно быть четным. А значит эйлеров путь существует только тогда, когда это число равно нулю или двум. Причём когда оно равно нулю, эйлеров путь вырождается в эйлеров цикл.
	+ *Эйлеров цикл* существует тогда и только тогда, когда граф связный, и в нём отсутствуют вершины нечётной степени.
- *В ориентированном графе*.
	+ Эйлеров путь, не являющейся циклом, тогда и только тогда, когда существуют две вершины `p ∈ V` и `q ∈ V` (начальная и конечная вершины пути соответственно) такие, что их полустепени захода и полустепени исхода связаны равенствами `indeg(q) = outdeg(q) + 1` и `indeg(p) = outdeg(p) - 1`, а все остальные вершины имеют одинаковые полустепени исхода и захода: `outdeg(v) = indeg(v)`.
	+ `G = (V, A)` содержит *эйлеров цикл* тогда и только тогда, когда он сильно связан и для каждой вершины графа её входящая степень `indeg(v)` равна её исходящей степени `outdeg(v)`, то есть в вершину входит столько же ребер, сколько из неё и выходит.

**Алгоритм поиска эйлерова цикла** (для ориентированных и неориентированных графов аналогичен):

```
st.push(s)
while not st.empty():
	v = st.top()
	for u in graph[v]:
		st.push(u)
		delete (v, u)
	if st.top() == v:
		print(v)
		st.pop()
```

> **Теорема**. Приведенный алгоритм корректен.
> 
> **Доказательство**. Понятно, что всякое ребро будет посещено и лишь один раз. Докажем, что порядок посещения вершин, который выведет алгоритм, будет выводить только смежные вершины.
> 
> 

# TODO: двусвязность, док-во

## Дерево доминаторов

Для графа `G` введем исток `s`. Говорят, что вершина `v` **доминирует над** `u`, если всякий путь из `s` в `u` проходит через вершину `v`. Пишется `v dom u`.

**Непосредственным доминатором** вершины `v` называется такая вершина `u`, что не существует такой вершины `t`, которая доминировала бы над `v` и при этом `t` лежит на пути между `v` и `u`. Другими словами, `u` -- ближайший к `v` доминатор. Пишется `idom(v) = u`.

> **Теорема**. Если `b dom a` и `c dom a`, то либо `c dom b`, либо `b dom c`.
> 
> **Доказательство**. Доминировать друг друга вершины `b` и `c` не могут, так как иначе `b = c` (по свойству антисимметричности). Осталось рассмотреть вариант, когда не `b dom c` и `c dom b`. Рассмотрим дерево обхода графа. Так как `b dom a` и `c dom a`, то любой путь в `a` содержит и `b`, и `c`. Но тогда либо `c dom b`, либо `b dom c`.

**Дерево доминаторов** -- это дерево, составленное из доминаторов. Ребро `(v, u)` существует тогда и только тогда, когда `idom(u) = v`.

**Тривиальный алгоритм**: удалим поочередно все вершины графа. `u dom v` тогда и только тогда, когда после удаления `u` вершина `v` стала недостижима.

Занумеруем вершины в порядке их обхода `dfs`. Рассмотрим типы ребер `(v, u)` в дереве обхода:

- **Ребра дерева**: `v < u`.
- **Прямые**: `v < u`.
- **Обратные**: `v > u`.
- **Перекрестные**: `v > u`.

> **Лемма**. Если в дереве доминаторов существует ребро `(v, u)` и `u > v`, то `u` в поддереве `v`.
> 
> **Доказательство**.

# TODO: построение за `O(MlogN)`

## Минимальный остов в неориентированном графе

**Остовное дерево** графа `G = (V, E)` -- ациклический связный (*дерево*) подграф данного связного неориентированного графа.

**Минимальное остовное дерево** графа `G = (V, E)` -- это его ациклический связный подграф, в который входят все его вершины, обладающий минимальным суммарным весом ребер.

**Ребро** `(u,v) ∉ G'` (`G'` -- *подграф некоторого минимального остовного дерева* `G`) называется **безопасным**, если при добавлении его в `G'`, `G' ∪ {(u,v)}` также является подграфом некоторого минимального остовного дерева графа `G`.

> **Лемма (о безопасном ребре)**. Рассмотрим связный неориентированный взвешенный граф `G = (V, E)` с весовой функцией `w: E → R`. Пусть `G' = (V, E′)` -- подграф некоторого минимального остовного дерева `G`, `⟨S,T⟩` -- разрез `G`, такой, что ни одно ребро из `E'` не пересекает разрез, а `(u,v)` -- ребро минимального веса среди всех ребер, пересекающих разрез `⟨S,T⟩`. Тогда ребро `e = (u, v)` является безопасным для `G'`.
> 
> **Доказательство**: Достроим `E'` до некоторого минимального остовного дерева, обозначим его `T_min`. Если ребро `e ∈ T_min`, то лемма доказана, поэтому рассмотрим случай, когда ребро `e ∉ T_min`. Рассмотрим путь в `T_min` от вершины `u` до вершины `v`. Так как эти вершины принадлежат разным долям разреза, то хотя бы одно ребро пути пересекает разрез, назовем его `e'`. По условию леммы `w(e) ⩽ w(e')`. Заменим ребро `e'` в `T_min` на ребро `e`. Полученное дерево также является минимальным остовным деревом графа `G`, поскольку все вершины `G` по-прежнему связаны и вес дерева не увеличился. Следовательно `E' ∪ {e}` можно дополнить до минимального остовного дерева в графе `G`, то есть ребро `e` -- безопасное.

*Алгоритмы построения минимального остовного дерева*:

**Алгоритм Краскала**:

1. Отсортируем ребра по их весу.
2. С использованием *DSU* будем добавлять (если вершины еще не соединены никаким путем) либо не добавлять ребро в минимальный остов.
3. Доказательство сводится к лемме о безопасном ребре.
4. Асимптотика `O(MlogM)`.

**Алгоритм Прима**:

1. Для каждой вершины (кроме стартовой) будем поддерживать минимальное входящее в нее ребро.
2. Будем поддерживать кучу вершин, отсортированных по минимальному входящему ребру (аналогично алгоритму Дейкстры).
3. Когда посещаем вершину -- добавляем ребро к ответу.
4. Асимптотика `O(E+Vlog(E/V)logV)` для двоичной кучи, `O((E+V)logV)` для двоичного дерева и `O(E+VlogV)` для фибоначчиевой кучи.

> **Теорема**. Алгоритм Прима корректен.
>
> **Доказательство**. По поддерживаемым инвариантам после извлечения вершины `v` (`v` ≠ `r`) из `Q` ребро `(v, p(v))` является ребром минимального веса, пересекающим разрез `(F, Q)`. Значит, по лемме о безопасном ребре, оно безопасно. Алгоритм построения *MST*, добавляющий безопасные ребра, причём делающий это ровно `V - 1 раз`, корректен. 

**Алгоритм Борувки**:

1. Изначально каждая вершина графа `G` -- тривиальное дерево, а ребра не принадлежат никакому дереву. 
2. Для каждого дерева `T` найдем минимальное инцидентное ему ребро. Добавим все такие ребра (без повторений).
3. Повторяем шаг 2 пока в графе не останется только одно дерево `T`.
4. Асимптотика `O(ElogV)`.

> **Теорема**. Алгоритм Борувки корректен.
> 
> **Доказательство**. Очевидно, что в результате работы алгоритма получается дерево. Пусть T - минимальное остовное дерево графа G, а T' - дерево полученное после работы алгоритма. Покажем, что T = T'.
>
> Предположим обратное: `T ≠ T'`. Пусть ребро `e'` - первое добавленное ребро дерева `T'`, не принадлежащее дереву `T`. Пусть `P` - путь, соединяющий в дереве `T` вершины ребра `e'`. Понятно, что в момент, когда ребро `e'` добавляли, какое-то ребро `P` (назовем его `e`) не было добавлено. По алгоритму `e ⩾ e'`. Однако тогда `T - e + e'` - остовное дерево веса не превышающего вес дерева `T`. Получили противоречение. Следовательно `T = T'`. 

**Алгоритм Фрейдмана-Тарьяна**.

Основан на *алгоритме Прима с фибоначчиевой кучей*.

Покажем, как будет работать одна **фаза** алгоритма. Фаза будет принимать значение `k` -- максимальное число ребер, которое может находиться в фибоначчиевой куче. Все связные компоненты для удобства сожмем в одну вершину. Запустим *алгоритм Прима* на каждой из этих компонент. Если в какой-то момент число вершин в куче больше либо равно, чем `k` -- остановим выполнение алгоритма. Иначе будем добавлять ребра аналогично алгоритму Прима. На следующей итерации (если не осталось компонент, которые имеют степень меньшую `k`) присвоим `k = 2^k`. Если осталась лишь одна компонента, то остов найден.

*Оценим асимптотику алгоритма при таком подходе*.

- Число компонент на итерации со значением `k` не превышает `2M/k`.
- Сумма работы всех `decrease_key` не превышает `O(M)`.
- Положим число компонент на данный момент равным `t`.
- В связи с ограничением на размер кучи, все операции извлечения минимума работают за `O(tlogk)`.
- Из фактов выше следует асимптотика на время работы одной итерации -- `O(M+tlogk)`.
- Присвоим `k_1` (`k` на первой итерации) значение 2.
- Подберем `k_i` так, чтобы `tlogk ~ M ~ 2M/k_i*log(k_(i+1))`. Тогда `k_i ~ log(k_(i+1))`.
- Тогда возьмем `k_(i+1) = 2^k_i`.
- Тогда получим, что каждая фаза работала за `O(M)`.
- Сложность алгоритма оценивается как `O(M) * число фаз`.
- Число фаз оценивается просто: это момент, когда `k_i` станет больше, чем `N`. Это есть итерированный логарифм, **поэтому общая асимптотика равна** `O(Mlog*N)`.

## Минимальный ориентированный остов

**Минимальный ориентированный остов** для вершины `s` в графе `G` -- это такое подмножество ребер минимального веса, что из `s` можно дойти до любой другой вершины графа.

Понятно, что данный остов содержит `N - 1` ребро, в противном случае можно было бы запустить `dfs` обход и взять дерево обхода графа. Из этого следует, что у любой вершины (кроме `s`) `indeg(v) = 1`.

*Рассмотрим следующее действие над графом* `G`: для каждой вершины (кроме корня) возьмем минимальное входящее в нее ребро. **Назовем этот граф** `G_0`.

> **Лемма**. `G_0` либо является минимальным ориентированным остовом, либо в нем есть циклы.
> 
> **Доказательство**. Очевидно, что если из `s` достижима любая вершина, то мы получили минимальный остов. Иначе рассмотрим вершину `v_1` из множествы вершин, не достижимых из `s`. У нее будет предок `v_2` из этого же множества (в противном случае она не входила бы в это множество), у `v_2` -- `v_3` и так далее. В какой-то момент вы придем к циклу, так как граф конечен.

> **Лемма (о сжатии цикла)**. Если `G_0` -- не остов, то для каждого цикла `C_1, C_2, ..., C_k` верно, что существует остов, использующий все ребра из него, кроме одного.
> 
> **Доказательство**. Рассмотрим такой минимальный остов `B`, что мощность множества `|B ⋂ (С_1 ∪ C_2 ∪ ... ∪ C_k)| = max` и один из циклов `C_i`. Пусть `e` -- некоторое ребро `(v, u)` в цикле, а `e'` -- ребро `(v', u)`, входящее в цикл, при этом `e ∈ C`, `e' ∈ B`. Удалим из `B` ребро `e'` и добавим вместо него `e'`. Рассмотрим то, что могло произойти:
> - Связность не поменяется. Тогда `w(B) - w(e') + w(e) ⩽ w(B)`. Получаем противоречие с условием `|B ⋂ (С_1 ∪ C_2 ∪ ... ∪ C_k)| = max`.
> - Связность поменялась. Тогда из этого следует, что мы получили цикл и между вершинами `v` и `u` существует путь в `B`. Рассмотрим `16 51:00`

**Алгоритм двух китайцев построения минимального остова**:

1. Для каждой вершины (кроме корня) возьмем минимальное входящее в нее ребро.
2. Если из получившегося графа достижимы все вершины -- ответ найден.
3. Иначе для каждой вершины отнимаем вес минимального вхдящего в нее ребра, сожмем циклы и запустим алгоритм на получившемся графе.
3. Асимптотика `O(VE)` (не более `V` конденсаций, каждая занимает `O(E)` операций).

# TODO: лемма о сжатии цикла, полиномиальный алгоритм

## Алгоритмы поиска кратчайшего пути во взвешенных графах

**Поиск в ширину (Breadth first search, BFS)** -- это метод обхода узлов в графе. *Может находить кратчайший путь в невзвешенном графе*. Асимптотика `O(V+E)`.

**0-k BFS** -- это разновидность *BFS*, предназначенная для использования на графах, где вес ребра -- это одно из чисел в пределах от 1 до `k`. Тогда для нахождения кратчайшего пути достаточно создать `k` очередей и выбирать вершину с минимальным номером очереди. Асимптотика `O(kV+E)`.

- Поддерживая список непустых очередей с помощью *кучи* можно ускорить до `O((V+E)logk)`.
- Можно оптимизировать до `O(V√k+E)` с помощью *sqrt-декомпозиции*.

**Алгоритм Дейкстры** (*работает только с неотрицательными весами ребер*):

1. Инициализируем все дистанции бесконечными, а вершину `s` -- нулевой дистанцией. Кладем `s` в кучу.
2. Пока куча не пуста: возьмем вершину `v` с минимальным текущим расстоянием и прорелаксируем ее.
3. Вернем кратчайшие расстояния.

> **Теорема**. Приведенный алгоритм корректен.
> 
> **Доказательство**. Докажем по индукции, что в момент посещения любой вершины `u`, `d(u) = D(u)`.
>
> 	- На первом шаге выбирается `s`, для неё выполнено: `D(s) = d(s) = 0`.
> 	- Пусть для `N` первых шагов алгоритм сработал верно и на `N+1` шагу выбрана вершина `u`. Докажем, что в этот момент `D(u) = d(u)`. Для начала отметим, что для любой вершины `v`, всегда выполняется `D(v) ⩾ d(v)` (алгоритм не может найти путь короче, чем кратчайший из всех существующих). Пусть `P` -- кратчайший путь из `s` в `u`, `v` -- первая непосещённая вершина на `P`, `z` -- предшествующая ей (следовательно, посещённая). Поскольку путь `P` кратчайший, его часть, ведущая из `s` через `z` в `v`, тоже кратчайшая, следовательно `d(v) = d(z) + w(zv)`. По предположению индукции, в момент посещения вершины `z` выполнялось `D(z) = d(z)`, следовательно, вершина `v` тогда получила метку не больше чем `D(z) + w(zv) = d(z) + w(zv) = D(v)`, следовательно, `D(v) = d(v)`. С другой стороны, поскольку сейчас мы выбрали вершину `u`, её метка минимальна среди непосещённых, то есть `D(u) ⩽ D(v) = d(v) ⩽ d(u)`, где второе неравенсто верно из-за ранее упомянутого определения вершины `v` в качестве первой непосещённой вершины на `P`, то есть вес пути до промежуточной вершины не превосходит веса пути до конечной вершины вследствие неотрицательности весовой функции. Комбинируя это с `D(u) ⩾ d(u)`, имеем `D(u) = d(u)`, что и требовалось доказать.
> 	- Поскольку алгоритм заканчивает работу, когда все вершины посещены, в этот момент `D(u) = d(u)` для всех `u`. 

*Ускорение с фибоначчиевой кучей* очевидно и тривиально: будем хранить указатель на узел в куче для каждой вершины и, если дистанция уменьшается, вместо того, чтобы добавлять в кучу новый узел, применим `decrease_key` на старом.

**Алгоритм Форда-Беллмана**:

1. Изначально `D[s] = 0, D[v] = ∞`.
2. На каждом из `V - 1 ` шагов рассматриваем все ребра и пытаемся улучшить ответ. Таким образом, на `k`-ом шаге мы найдем все пути длины k. Понятно, что на 0 шаге индукция верна, и на каждом шаге будет найдено ребро, которое установит кратчайший путь.
3. Асимптотика `O(VE)`.

Стоит обратить внимание на следующий факт: *алгоритм способен находить циклы отрицательного веса*.

Для указания *существования* циклов: введем `V`-ю итерацию. Действительно, если циклов отрицательного веса нет, то обновлений кратчайших путей не будет. Иначе найдется кратчайший путь, который имеет длину `V`, чего быть не может.

Для *поиска* циклов: введем дополнительные `V` итераций. Понятно, что всякий отрицательный цикл за это время полностью обновится. Тогда запустим `dfs` из всех вершин, для которых за `V` дополнительных итераций произошло обновление и укажем бесконечное расстояние до них.

**Алгоритм SPFA (Shortest Path Faster Algorithm)** (улучшение алгоритма Форда-Беллмана):

1. Изначально `D[s] = 0, D[v] = ∞`, `s` добавим в очередь.
2. Пока очередь не пуста: возьмем вершину `v`. Попробуем улучшить для всех соседних вершин `u` результат. Если он был улучшен -- добавим вершину в очередь (если ее там еще не было). Очевидно, что каждая вершина побывает в очереди в тот момент, когда для нее путь кратчайший.

**Алгоритм Флойда** (*находит кратчайшие пути между* **всеми** *парами вершин*):

1. Изначально `D[v, v] = 0`, если существует ребро `(v, u)` веса `w`, то `D[v, u] = w`, иначе `D[v, u] = ∞`.
2. Перебираем вершину, через которую путь пойдет, стартовую и конечную.

```
for k = 1 to n
	for i = 1 to n
		for j = 1 to n
			D[i, j] = min(D[i, j], D[i, k] + D[k, j])
```

## Алгоритм Торупа

# TODO

## Паросочетания

**Паросочетание** `M` -- это набор попарно несмежных рёбер графа.

**Мощность паросочетания** -- количество рёбер в нём.

**Наибольшее (или максимальное) паросочетание** -- паросочетание, мощность которого максимальна среди всех возможных паросочетаний в данном графе.

**Цепью** длины `k` назовём некоторый простой путь (то есть не содержащий повторяющихся вершин или рёбер), содержащий `k` рёбер.

**Чередующейся цепью** (в двудольном графе, относительно некоторого паросочетания) назовём цепь, в которой рёбра поочередно принадлежат/не принадлежат паросочетанию.

**Увеличивающей цепью** (в двудольном графе, относительно некоторого паросочетания) назовём чередующуюся цепь, у которой начальная и конечная вершины не принадлежат паросочетанию.

> **Теорема (Берж)**. Паросочетание является максимальным тогда и только тогда, когда не существует увеличивающих относительно него цепей.
> 
> **Доказательство**.
> 
> - `=>`: Пусть паросочетание максимально, но существует увеличивающая цепь. Тогда поменяем состояние всех ребер вдоль цепи и получим паросочетание на 1 большего размера. Паросочетание останется корректным, так как по условию две крайние вершины были ненасыщенными, а остальные не могли входить в паросочетание кроме данного.
> - `<=`: Докажем, что если относительно некоторого паросочетания `M` нет увеличивающих путей, то оно — максимально. Доказательство проведём от противного.
> 
>	- Пусть есть паросочетание `M'`, имеющее большую мощность, чем `M`. Рассмотрим симметрическую разность `Q` этих двух паросочетаний, то есть оставим все рёбра, входящие в `M` или в `M'`, но не в оба одновременно.
>	- Понятно, что множество рёбер `Q` -- уже наверняка не паросочетание. Рассмотрим, какой вид это множество рёбер имеет; для удобства будем рассматривать его как граф. В этом графе каждая вершина, очевидно, имеет степень не выше 2 (потому что каждая вершина может иметь максимум два смежных ребра — из одного паросочетания и из другого). Легко понять, что тогда этот граф состоит только из циклов или путей, причём ни те, ни другие не пересекаются друг с другом.
>	- Теперь заметим, что и пути в этом графе `Q` могут быть не любыми, а только чётной длины. В самом деле, в любом пути в графе Q рёбра чередуются: после ребра из M идёт ребро из `M'`, и наоборот. Теперь, если мы рассмотрим какой-то путь нечётной длины в графе `Q`, то получится, что в исходном графе `G` это будет увеличивающей цепью либо для паросочетания `M`, либо для `M'`. Но этого быть не могло, потому что в случае паросочетания `M` это противоречит с условием, а в случае `M'` -- с его максимальностью (ведь мы уже доказали необходимость теоремы, из которой следует, что при существовании увеличивающей цепи паросочетание не может быть максимальным).
>	- Докажем теперь аналогичное утверждение и для циклов: все циклы в графе `Q` могут иметь только чётную длину. Это доказать совсем просто: понятно, что в цикле рёбра также должны чередоваться (принадлежать по очереди то `M`, то `M'`), но это условие не может выполниться в цикле нечётной длины -- в нём обязательно найдутся два соседних ребра из одного паросочетания, что противоречит определению паросочетания.
>	- Таким образом, все пути и циклы графа `Q = M △ M'` имеют чётную длину. Следовательно, граф `Q` содержит равное количество рёбер из `M` и из `M'`. Но, учитывая, что в `Q` содержатся все рёбра `M` и `M'`, за исключением их общих рёбер, то отсюда следует, что мощность `M` и `M'` совпадают. Мы пришли к противоречию: по предположению паросочетание `M` было не максимальным, значит, теорема доказана.

**Алгоритм Куна**:

1. Из каждой ненасыщенной вершины попробуем найти увеличивающую цепь.
2. Для всех соседей `u`: если вершина `u` ненасыщенна -- добавим паросочетание `(v, u)`.
3. Асимптотика `O(VE)`.

```
used[] = {}
pairs[] = {}
graph[,] = {...}

func dfs(v)
	used[v] = true
	for u in graph[v]:
		if (mt[to] == -1 || (not used[u] and dfs(pairs[u]))):
			pairs[u] = v
			return true
	return false

func kuhn():
	for v in range(n):
		used.assign(n, false)
		dfs(v)
```

Данный алгоритм выгодно *запускать только из вершин меньшей доли*, если разбиение на доли известно. Тогда асимптотика `O(V_1*E)`.

37:23
